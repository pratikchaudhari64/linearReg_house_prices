{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_validate, StratifiedKFold, KFold, GridSearchCV, LearningCurveDisplay\n",
    "from sklearn.metrics import PredictionErrorDisplay, root_mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "from utils import plot_outlier_analysis, residual_plots\n",
    "\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "y = dataset[['SalePrice']]\n",
    "log1p_y = np.log1p(y)\n",
    "X = dataset.drop(['SalePrice', 'Id'], axis = 1)\n",
    "\n",
    "testset = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_to_category = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape',\n",
    "                   'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \n",
    "                   'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                   'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "                   'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', \n",
    "                   'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                   'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', \n",
    "                   'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
    "                   'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n",
    "                   'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n",
    "                'SaleType', 'SaleCondition']\n",
    "\n",
    "chg_to_numer = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', \n",
    "                'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "                'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "                'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "                'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n",
    "                'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', \n",
    "                'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold',\n",
    "                'MoSold'\n",
    "                ]\n",
    "\n",
    "numerical_selector = make_column_selector(dtype_include=['int64', 'float64'])\n",
    "cat_selector = make_column_selector(dtype_include=['object'])\n",
    "\n",
    "X[chg_to_numer] = X[chg_to_numer].astype('float64')\n",
    "X[chg_to_category] = X[chg_to_category].astype('object')\n",
    "\n",
    "testset[chg_to_numer] = testset[chg_to_numer].astype('float64')\n",
    "testset[chg_to_category] = testset[chg_to_category].astype('object')\n",
    "\n",
    "continous_num = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                 '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                 'EnclosedPorch', '3SsnPorch',\t'ScreenPorch',\t'PoolArea',\t'MiscVal']\n",
    "\n",
    "time_based_num = ['MoSold', 'YrSold', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt']\n",
    "\n",
    "discrete_num = list(set(chg_to_numer) - set(continous_num) - set(time_based_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>189.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>...</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "      <td>220.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.810</td>\n",
       "      <td>8611.623</td>\n",
       "      <td>5.532</td>\n",
       "      <td>5.845</td>\n",
       "      <td>1956.241</td>\n",
       "      <td>1976.682</td>\n",
       "      <td>82.991</td>\n",
       "      <td>387.523</td>\n",
       "      <td>33.736</td>\n",
       "      <td>504.305</td>\n",
       "      <td>...</td>\n",
       "      <td>412.145</td>\n",
       "      <td>62.032</td>\n",
       "      <td>33.750</td>\n",
       "      <td>35.932</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12.886</td>\n",
       "      <td>0.000</td>\n",
       "      <td>113.000</td>\n",
       "      <td>6.450</td>\n",
       "      <td>2007.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.090</td>\n",
       "      <td>4213.934</td>\n",
       "      <td>1.229</td>\n",
       "      <td>1.128</td>\n",
       "      <td>28.571</td>\n",
       "      <td>22.237</td>\n",
       "      <td>169.648</td>\n",
       "      <td>373.764</td>\n",
       "      <td>128.409</td>\n",
       "      <td>342.343</td>\n",
       "      <td>...</td>\n",
       "      <td>214.892</td>\n",
       "      <td>104.998</td>\n",
       "      <td>56.553</td>\n",
       "      <td>73.311</td>\n",
       "      <td>0.000</td>\n",
       "      <td>49.414</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1064.408</td>\n",
       "      <td>2.635</td>\n",
       "      <td>1.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000</td>\n",
       "      <td>1300.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1872.000</td>\n",
       "      <td>1950.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2006.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000</td>\n",
       "      <td>6240.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1938.000</td>\n",
       "      <td>1952.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>261.750</td>\n",
       "      <td>...</td>\n",
       "      <td>280.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2007.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000</td>\n",
       "      <td>8402.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1956.000</td>\n",
       "      <td>1973.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>367.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>468.000</td>\n",
       "      <td>...</td>\n",
       "      <td>404.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>2008.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000</td>\n",
       "      <td>10328.750</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>1971.250</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>116.250</td>\n",
       "      <td>604.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>747.250</td>\n",
       "      <td>...</td>\n",
       "      <td>528.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2009.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>138.000</td>\n",
       "      <td>35133.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>2009.000</td>\n",
       "      <td>2009.000</td>\n",
       "      <td>1129.000</td>\n",
       "      <td>1696.000</td>\n",
       "      <td>1029.000</td>\n",
       "      <td>1869.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1356.000</td>\n",
       "      <td>495.000</td>\n",
       "      <td>285.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>288.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15500.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>2010.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "count      189.000   220.000      220.000      220.000    220.000   \n",
       "mean        62.810  8611.623        5.532        5.845   1956.241   \n",
       "std         19.090  4213.934        1.229        1.128     28.571   \n",
       "min         24.000  1300.000        3.000        2.000   1872.000   \n",
       "25%         50.000  6240.000        5.000        5.000   1938.000   \n",
       "50%         60.000  8402.500        5.000        6.000   1956.000   \n",
       "75%         73.000 10328.750        6.000        7.000   1971.250   \n",
       "max        138.000 35133.000        9.000        9.000   2009.000   \n",
       "\n",
       "       YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "count       220.000     220.000     220.000     220.000    220.000  ...   \n",
       "mean       1976.682      82.991     387.523      33.736    504.305  ...   \n",
       "std          22.237     169.648     373.764     128.409    342.343  ...   \n",
       "min        1950.000       0.000       0.000       0.000      0.000  ...   \n",
       "25%        1952.250       0.000       0.000       0.000    261.750  ...   \n",
       "50%        1973.500       0.000     367.000       0.000    468.000  ...   \n",
       "75%        2000.000     116.250     604.750       0.000    747.250  ...   \n",
       "max        2009.000    1129.000    1696.000    1029.000   1869.000  ...   \n",
       "\n",
       "       GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "count     220.000     220.000      220.000        220.000    220.000   \n",
       "mean      412.145      62.032       33.750         35.932      0.000   \n",
       "std       214.892     104.998       56.553         73.311      0.000   \n",
       "min         0.000       0.000        0.000          0.000      0.000   \n",
       "25%       280.000       0.000        0.000          0.000      0.000   \n",
       "50%       404.500       0.000        0.000          0.000      0.000   \n",
       "75%       528.000     120.000       50.000          0.000      0.000   \n",
       "max      1356.000     495.000      285.000        330.000      0.000   \n",
       "\n",
       "       ScreenPorch  PoolArea   MiscVal  MoSold   YrSold  \n",
       "count      220.000   220.000   220.000 220.000  220.000  \n",
       "mean        12.886     0.000   113.000   6.450 2007.755  \n",
       "std         49.414     0.000  1064.408   2.635    1.266  \n",
       "min          0.000     0.000     0.000   1.000 2006.000  \n",
       "25%          0.000     0.000     0.000   5.000 2007.000  \n",
       "50%          0.000     0.000     0.000   6.000 2008.000  \n",
       "75%          0.000     0.000     0.000   8.000 2009.000  \n",
       "max        288.000     0.000 15500.000  12.000 2010.000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FEATURE ENGINEERING\n",
    "\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# X[time_based_num]\n",
    "# X.loc[:, 'age_at_remodel'] = X['YearRemodAdd'] - X['YearBuilt']\n",
    "# X.loc[:, 'age_at_sell'] = X['YrSold'] - X['YearBuilt']\n",
    "\n",
    "X_fortree = pd.get_dummies(X)\n",
    "\n",
    "dtr = DecisionTreeRegressor().fit(X_fortree, y)\n",
    "dtr\n",
    "# dir(dtr.tree_)\n",
    "# dtr.tree_.impurity\n",
    "# plot_tree(dtr, max_depth = 10, feature_names = dtr.feature_names_in_)\n",
    "# plt.savefig('tree.pdf')\n",
    "\n",
    "# cv_res = cross_validate(DecisionTreeRegressor(random_state=0),\n",
    "#                pd.get_dummies(X), y,\n",
    "#                scoring='neg_root_mean_squared_error',\n",
    "#                return_train_score=True)\n",
    "\n",
    "# pd.DataFrame(cv_res)\n",
    "\n",
    "X[X['Exterior1st'] == 'MetalSd'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING TIMELINE\n",
    "\n",
    "def mod_ordinal_transform(X, imputer):\n",
    "\n",
    "    missing_imputer = imputer\n",
    "\n",
    "    testset = pd.read_csv(\"test.csv\")\n",
    "    trainset = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    full_data = pd.concat([trainset, testset])\n",
    "\n",
    "    #Fitting imputer on test+train set for consistent ordinal encoding\n",
    "    missing_imputer.fit(full_data[chg_to_category])\n",
    "    imputed_values_fulldata = pd.DataFrame(missing_imputer.transform(full_data[chg_to_category]))\n",
    "    imputed_values_fulldata.columns = missing_imputer.get_feature_names_out()\n",
    "\n",
    "    enc = OrdinalEncoder().fit(imputed_values_fulldata)\n",
    "\n",
    "\n",
    "    X_imputed = pd.DataFrame(missing_imputer.transform(X[chg_to_category]))\n",
    "    X_imputed.columns = missing_imputer.get_feature_names_out()\n",
    "\n",
    "    X_transf = pd.DataFrame(enc.transform(X_imputed))\n",
    "\n",
    "    X_transf.columns = enc.get_feature_names_out()\n",
    "    X_transf.index = X.index\n",
    "    X_transf = X_transf[chg_to_category]\n",
    "\n",
    "    return X_transf\n",
    "\n",
    "\n",
    "preprocessors = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), numerical_selector),\n",
    "     (\"enc\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_selector)]\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "preprocessors_2 = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), numerical_selector),\n",
    "     (\"enc\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_selector)]\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "preprocessors_3 = ColumnTransformer(\n",
    "    [(\"scaler\", StandardScaler(), numerical_selector),\n",
    "     (\"enc\", OneHotEncoder(handle_unknown='infrequent_if_exist'), cat_selector)]\n",
    "    )\n",
    "\n",
    "preprocessors_4 = ColumnTransformer(\n",
    "    [(\"scaler\", PowerTransformer(method='yeo-johnson', standardize=True), numerical_selector),\n",
    "     (\"enc\", OneHotEncoder(handle_unknown='infrequent_if_exist'), cat_selector)]\n",
    "    )\n",
    "\n",
    "\n",
    "preprocessors_6 = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"scaler\", StandardScaler(), numerical_selector),\n",
    "        (\"enc\", FunctionTransformer(mod_ordinal_transform, \n",
    "                                    validate=False, \n",
    "                                    kw_args={'imputer': SimpleImputer(strategy='constant', fill_value='not available')}), \n",
    "                                    chg_to_category)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "preprocessors_7 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cont_num\", PowerTransformer(method='yeo-johnson', standardize=True), continous_num),\n",
    "        (\"time_num\", StandardScaler(), time_based_num),\n",
    "        (\"discrete_num\", OneHotEncoder(handle_unknown='infrequent_if_exist'), discrete_num),\n",
    "        (\"enc\", OneHotEncoder(handle_unknown='infrequent_if_exist'), chg_to_category)\n",
    "    ],\n",
    "    verbose_feature_names_out = False\n",
    ")\n",
    "\n",
    "# pd.DataFrame(preprocessors.fit_transform(X))\n",
    "\n",
    "missing_imputer = ColumnTransformer(\n",
    "    [(\"num_mean\", SimpleImputer(strategy='mean'), numerical_selector),\n",
    "     (\"cat_ordinal\", SimpleImputer(strategy='most_frequent'), cat_selector)]\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "\n",
    "missing_imputer_2 = ColumnTransformer(\n",
    "    [(\"num_mean\", SimpleImputer(strategy = 'constant', fill_value=0), chg_to_numer),\n",
    "     (\"cat_ordinal\", SimpleImputer(strategy='constant', fill_value='NA'), chg_to_category)]\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "missing_imputer_3 = ColumnTransformer(\n",
    "    [(\"num_mean\", KNNImputer(n_neighbors=5), chg_to_numer),\n",
    "     (\"cat_ordinal\", SimpleImputer(strategy='constant', fill_value='not available'), chg_to_category)],\n",
    "        verbose_feature_names_out = False\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "missing_imputer_4 = ColumnTransformer(\n",
    "    [(\"num_mean\", KNNImputer(n_neighbors=5), chg_to_numer),\n",
    "     (\"cat_ordinal\", SimpleImputer(strategy='most_frequent'), chg_to_category)],\n",
    "     verbose_feature_names_out=False\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "missing_imputer_5 = ColumnTransformer(\n",
    "    [(\"num_mean\", SimpleImputer(strategy='mean'), chg_to_numer),\n",
    "     (\"cat_ordinal\", SimpleImputer(strategy='most_frequent'), chg_to_category)]\n",
    "    ).set_output(transform='pandas')\n",
    "\n",
    "\n",
    "# pd.DataFrame(preprocessors_2.fit_transform(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH FOR PREPROCESSING AND ESTIMATOR PIPELINE \n",
    "\n",
    "linearReg_pipe = Pipeline([\n",
    "    ('missing_imputer', missing_imputer),\n",
    "    ('preprocessor', preprocessors),\n",
    "    ('linearreg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "# param_grid = [{\n",
    "#     'missing_imputer': [missing_imputer, missing_imputer_2, missing_imputer_3, missing_imputer_4, missing_imputer_5],\n",
    "#     'preprocessor': [preprocessors, preprocessors_2, preprocessors_3, preprocessors_4, preprocessors_6],\n",
    "#     'linearreg': [LinearRegression(), RidgeCV(), Ridge()]\n",
    "# }]\n",
    "\n",
    "imputers = [missing_imputer_2, missing_imputer_3, missing_imputer_4, missing_imputer_5]\n",
    "preprocesrs = [preprocessors_2, preprocessors_3, preprocessors_4, preprocessors_6, preprocessors_7]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'missing_imputer': imputers,\n",
    "        'preprocessor': preprocesrs,\n",
    "        'linearreg': [LinearRegression()],\n",
    "        'linearreg__fit_intercept': [True, False]\n",
    "    },\n",
    "    {\n",
    "        'missing_imputer': imputers,\n",
    "        'preprocessor': preprocesrs,\n",
    "        'linearreg': [RidgeCV()],\n",
    "        'linearreg__alphas': [(0.1, 1.0, 10.0), (0.01, 0.1, 1.0, 10.0), (0.001, 0.01, 0.1, 10, 100.0)],\n",
    "        'linearreg__fit_intercept': [True, False],\n",
    "        'linearreg__gcv_mode': ['auto', 'svd', 'eigen']\n",
    "    },\n",
    "    {\n",
    "        'missing_imputer': imputers,\n",
    "        'preprocessor': preprocesrs,\n",
    "        'linearreg': [Ridge()],\n",
    "        'linearreg__alpha': [0.1, 1.0, 10.0, 100.0],\n",
    "        'linearreg__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "    },\n",
    "    {\n",
    "        'missing_imputer': imputers,\n",
    "        'preprocessor': preprocesrs,\n",
    "        'linearreg': [SGDRegressor()],\n",
    "        'linearreg__alpha': np.linspace(0.00001, 10, num=5),\n",
    "        'linearreg__penalty': ['elasticnet'],\n",
    "        'linearreg__l1_ratio': np.linspace(0.01, 1, num=5)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Set up and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(linearReg_pipe, \n",
    "                           param_grid, \n",
    "                           cv=5, scoring='neg_root_mean_squared_error', \n",
    "                           return_train_score=True,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X, log1p_y)\n",
    "\n",
    "# Get the best parameters and scores\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "pd.DataFrame(grid_search.cv_results_).sort_values(by=['rank_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual cross fold\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(kf.split(dataset)):\n",
    "#     dataset.loc[test_index, 'kfold'] = i\n",
    "\n",
    "# for i in dataset['kfold'].unique():\n",
    "#     validation_set = dataset[dataset['kfold'] == i]\n",
    "#     train_set = dataset[dataset['kfold'] != i]\n",
    "#     y_train = train_set[['SalePrice']]\n",
    "#     y_validation = validation_set[['SalePrice']]\n",
    "\n",
    "#     validation_set = validation_set.drop(columns=['Id', 'SalePrice', 'kfold'])\n",
    "#     train_set = train_set.drop(columns=['Id', 'SalePrice', 'kfold'])\n",
    "\n",
    "#     model_pipe.fit(train_set, y_train)\n",
    "\n",
    "#     # if i == 3:\n",
    "#     #     display(model_pipe[:-1].fit_transform(validation_set)['Utilities'].value_counts())\n",
    "\n",
    "#     #     display(pd.DataFrame(model_pipe[2].coef_))\n",
    "#     #     display(model_pipe[:-1].fit_transform(validation_set))\n",
    "\n",
    "#     display(f\"\"\"fold: {i}, \n",
    "#             train_score: {model_pipe.score(train_set, y_train)}, \n",
    "#             test_score:{model_pipe.score(validation_set, y_validation)},\n",
    "#             rmse = {root_mean_squared_error(y_validation, model_pipe.predict(validation_set))}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plots for comparison\n",
    "\n",
    "# display(reg_model.score(X, y))\n",
    "# residual_plots(model = reg_model, data=X, y=y)\n",
    "\n",
    "# display(reg_model_2.score(X, y))\n",
    "# residual_plots(model = reg_model_2, data=X, y=y)\n",
    "\n",
    "# display(reg_model_3.score(X, y))\n",
    "# residual_plots(model = reg_model_3, data=X, y=y)\n",
    "\n",
    "# # Best So FAR: reg_model_4\n",
    "\n",
    "# display(reg_model_4.score(X, y))\n",
    "# residual_plots(model = reg_model_4, data=X, y=y)\n",
    "\n",
    "# display(reg_model_5.score(X, y))\n",
    "# residual_plots(model = reg_model_5, data=X, y=y)\n",
    "\n",
    "best_gridsearchCV_pipe = Pipeline([\n",
    "    ('missing_imputer', grid_search.best_params_['missing_imputer']),\n",
    "    ('preprocessor', grid_search.best_params_['preprocessor']),\n",
    "    ('linearreg', grid_search.best_params_['linearreg'])\n",
    "])\n",
    "best_gridsearchCV_pipe.fit(X, log1p_y)\n",
    "display(best_gridsearchCV_pipe.score(X, log1p_y))\n",
    "residual_plots(model = best_gridsearchCV_pipe, data=X, y=log1p_y)\n",
    "# grid_search.best_params_\n",
    "# pd.DataFrame(best_gridsearchCV_pipe[1].fit_transform(X).toarray())\n",
    "# best_gridsearchCV_pipe[0].fit_transform(X)\n",
    "# X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_res = cross_validate(best_gridsearchCV_pipe,\n",
    "                        X, log1p_y,\n",
    "                        scoring=('neg_root_mean_squared_error', 'r2'),\n",
    "                        cv = 5, return_train_score=True)\n",
    "cv_res = pd.DataFrame(cv_res)\n",
    "display(f\"mean_test : {cv_res['test_neg_root_mean_squared_error'].mean()}, mean_train : {cv_res['train_neg_root_mean_squared_error'].mean()}, {cv_res['test_r2'].mean()}; {cv_res['train_r2'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subm = testset[['Id']].join(pd.DataFrame(best_gridsearchCV_pipe.predict(testset), columns=['SalePrice']))\n",
    "# subm[['SalePrice']] = np.expm1(subm[['SalePrice']])\n",
    "# subm.to_csv('submissions/grid_search_3_imp2_p4_ridge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEARNING CURVE OF MODEL\n",
    "\n",
    "\n",
    "\n",
    "# Create train sizes (10% to 100%)\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "\n",
    "LearningCurveDisplay.from_estimator(\n",
    "    best_gridsearchCV_pipe,\n",
    "    X, y,\n",
    "    train_sizes= train_sizes,\n",
    "    scoring = 'r2',\n",
    "    std_display_style = 'errorbar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE Experiment\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.optimize import minimize\n",
    "# from scipy.stats import t\n",
    "\n",
    "# # Generate synthetic data\n",
    "# np.random.seed(42)\n",
    "# X = np.random.normal(size=(100, 1))\n",
    "# beta = np.array([2.5])\n",
    "# epsilon = np.random.standard_t(df=3, size=100)  # t-distribution errors\n",
    "# y = X.dot(beta) + epsilon\n",
    "\n",
    "# # Define the log-likelihood function for t-distribution\n",
    "# def log_likelihood(params):\n",
    "#     beta = params[:-1]\n",
    "#     df = params[-1]\n",
    "#     residuals = y - X.dot(beta)\n",
    "    \n",
    "#     likelihood = np.prod(t.pdf(residuals, df=df)) \n",
    "#     print(f\"Likelihood: {likelihood}\")\n",
    "\n",
    "#     log_likelihood = np.sum(t.logpdf(residuals, df=df))\n",
    "#     return -log_likelihood\n",
    "\n",
    "# # Initial guess for parameters\n",
    "# initial_params = np.append(np.ones(X.shape[1]), 3.0)\n",
    "\n",
    "# # Optimize the log-likelihood function\n",
    "# result = minimize(log_likelihood, initial_params, method='BFGS')  # You can try different methods like 'L-BFGS-B', 'Nelder-Mead', etc.\n",
    "\n",
    "# # Extract estimated parameters\n",
    "# beta_est = result.x[:-1]\n",
    "# df_est = result.x[-1]\n",
    "\n",
    "# print(f\"Estimated beta: {beta_est}\")\n",
    "# print(f\"Estimated degrees of freedom: {df_est}\")\n",
    "# log_likelihood(initial_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
