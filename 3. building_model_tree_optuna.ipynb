{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import joblib\n",
    "import dill\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_validate, StratifiedKFold, KFold, GridSearchCV, LearningCurveDisplay\n",
    "from sklearn.metrics import PredictionErrorDisplay, root_mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "from preprocessors import missing_imputers, feat_engg\n",
    "\n",
    "import optuna\n",
    "from plotly.io import show\n",
    "\n",
    "\n",
    "from utils import plot_outlier_analysis, residual_plots\n",
    "\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "y = dataset[['SalePrice']]\n",
    "log1p_y = np.log1p(y)\n",
    "X = dataset.drop(['SalePrice', 'Id'], axis = 1)\n",
    "\n",
    "fulltestset = pd.read_csv('test.csv')\n",
    "testset = fulltestset.drop(['Id'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_to_category = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape',\n",
    "                   'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \n",
    "                   'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                   'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "                   'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', \n",
    "                   'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                   'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', \n",
    "                   'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
    "                   'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n",
    "                   'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n",
    "                'SaleType', 'SaleCondition']\n",
    "\n",
    "chg_to_numer = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', \n",
    "                'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "                'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "                'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "                'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n",
    "                'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', \n",
    "                'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold',\n",
    "                'MoSold'\n",
    "                ]\n",
    "\n",
    "numerical_selector = make_column_selector(dtype_include=['int64', 'float64'])\n",
    "cat_selector = make_column_selector(dtype_include=['object'])\n",
    "\n",
    "X[chg_to_numer] = X[chg_to_numer].astype('float64')\n",
    "X[chg_to_category] = X[chg_to_category].astype('object')\n",
    "\n",
    "testset[chg_to_numer] = testset[chg_to_numer].astype('float64')\n",
    "testset[chg_to_category] = testset[chg_to_category].astype('object')\n",
    "\n",
    "continous_num = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                 '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                 'EnclosedPorch', '3SsnPorch',\t'ScreenPorch',\t'PoolArea',\t'MiscVal']\n",
    "\n",
    "time_based_num = ['MoSold', 'YrSold', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt']\n",
    "\n",
    "discrete_num = list(set(chg_to_numer) - set(continous_num) - set(time_based_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imputer = missing_imputers()\n",
    "data_prep = feat_engg(trainset=X, testset=testset)\n",
    "\n",
    "cols_list = [numerical_selector, chg_to_category]\n",
    "prep8 = data_prep.prep8(*cols_list)\n",
    "\n",
    "\n",
    "dtr = Pipeline(\n",
    "    [\n",
    "        ('prep', prep8),\n",
    "        ('tree', DecisionTreeRegressor(random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "dtr.fit(X, y)\n",
    "\n",
    "\n",
    "tree_preds = pd.DataFrame(dtr.predict(testset), columns=['SalePrice'])\n",
    "tree_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(dtr,\n",
    "                                X, y,\n",
    "                                cv=5,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                return_train_score=True)\n",
    "pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "path = dtr[1].cost_complexity_pruning_path(dtr[0].fit_transform(X), y)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "# ccp_alphas[:-1]\n",
    "# ccp_alphas\n",
    "path = pd.DataFrame(path)\n",
    "path.sort_values(by=['ccp_alphas'])\n",
    "# path = path[path['impurities'] <= 100000000]\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to optimise\n",
    "# ccp_alphas, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None\n",
    "\n",
    "# Define an objective function to be minimized.\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    ccp_alphas_trials = trial.suggest_categorical('tree__ccp_alpha', ccp_alphas)\n",
    "    max_depth_trials = trial.suggest_categorical('tree__max_depth', np.arange(5, 36, 5))\n",
    "    min_samples_split_trials = trial.suggest_categorical('tree__min_samples_split', np.arange(30, 100, 10))\n",
    "    min_samples_leaf_trials = trial.suggest_categorical('tree__min_samples_leaf', np.arange(20, 100, 10))\n",
    "    # min_impurity_decrease_trials = trial.suggest_categorical('min_impurity_decrease', np.arange(0, 2, 5))\n",
    "\n",
    "    dtr = Pipeline(\n",
    "        [\n",
    "            ('prep', prep8),\n",
    "            ('tree', DecisionTreeRegressor(random_state=0, \n",
    "                                           ccp_alpha = ccp_alphas_trials,\n",
    "                                           max_depth=max_depth_trials,\n",
    "                                           min_samples_split = min_samples_split_trials,\n",
    "                                           min_samples_leaf=min_samples_leaf_trials)\n",
    "                                           )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cv_results = cross_validate(dtr,\n",
    "                                X, y,\n",
    "                                cv=5,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                return_train_score=True)\n",
    "\n",
    "    # regressor_obj.fit(X_train, y_train)\n",
    "    # y_pred = regressor_obj.predict(X_val)\n",
    "\n",
    "    error = pd.DataFrame(cv_results)['test_score'].mean()\n",
    "\n",
    "    return error  # An objective value linked with the Trial object.\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # Create a new study.\n",
    "study.optimize(objective, n_trials=100)  # Invoke optimization of the objective function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.io import show\n",
    "\n",
    "# display(study.best_params)\n",
    "# dir(study)\n",
    "dtr.set_params(**study.best_params)\n",
    "dtr.get_params()\n",
    "# cv_res = cross_validate(dtr,\n",
    "#                X, y, cv = 5, return_train_score=True, scoring='neg_mean_squared_error')\n",
    "\n",
    "# pd.DataFrame(cv_res)\n",
    "\n",
    "# dtr[1].feature_importances_\n",
    "# dtr[1].feature_names_in_\n",
    "# feat_imp = pd.DataFrame(\n",
    "#     {\n",
    "#         'feature_names_in': dtr[1].feature_names_in_,\n",
    "#         'feature_importances_': dtr[1].feature_importances_\n",
    "#     }\n",
    "# ).sort_values(by=['feature_importances_'], ascending=False)\n",
    "# feat_imp[feat_imp['feature_importances_'] > 0.1]\n",
    "# pd.DataFrame(dtr[1].tree_.impurity[np.where(dtr[1].tree_.children_left == -1)[0]]).mean()\n",
    "# pd.DataFrame(dtr[1].tree_.impurity)\n",
    "pd.DataFrame(dtr[1].tree_.n_node_samples[np.where(dtr[1].tree_.children_left != -1)[0]]).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree__ccp_alpha, tree__max_depth, tree__min_samples_split, tree__min_samples_leaf\n",
    "\n",
    "fig = optuna.visualization.plot_contour(study, params=[\"tree__max_depth\", \"tree__min_samples_split\", \"tree__min_samples_leaf\", \"tree__ccp_alpha\"])\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING MODELS AND PREDICT FOR SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtr[1].get_params()\n",
    "# with open('models/base_decisiontree_1_pre_post_pruning.pkl', 'wb') as f: \n",
    "#     dill.dump(dtr, f)\n",
    "\n",
    "# tree_preds = pd.DataFrame(dtr.predict(testset), columns=['SalePrice'])\n",
    "# fulltestset[['Id']].join(tree_preds)\n",
    "# fulltestset[['Id']].join(tree_preds).to_csv('submissions/base_decisiontree_1_pre_post_pruning.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
