{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import joblib\n",
    "import dill\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, SGDRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_validate, StratifiedKFold, KFold, GridSearchCV, LearningCurveDisplay\n",
    "from sklearn.metrics import PredictionErrorDisplay, root_mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "from utils import plot_outlier_analysis, residual_plots\n",
    "\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "y = dataset[['SalePrice']]\n",
    "log1p_y = np.log1p(y)\n",
    "X = dataset.drop(['SalePrice', 'Id'], axis = 1)\n",
    "\n",
    "fulltestset = pd.read_csv('test.csv')\n",
    "testset = fulltestset.drop(['Id'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_to_category = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape',\n",
    "                   'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \n",
    "                   'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "                   'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "                   'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', \n",
    "                   'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                   'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', \n",
    "                   'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
    "                   'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n",
    "                   'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n",
    "                'SaleType', 'SaleCondition']\n",
    "\n",
    "chg_to_numer = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', \n",
    "                'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "                'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
    "                'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "                'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n",
    "                'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', \n",
    "                'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold',\n",
    "                'MoSold'\n",
    "                ]\n",
    "\n",
    "numerical_selector = make_column_selector(dtype_include=['int64', 'float64'])\n",
    "cat_selector = make_column_selector(dtype_include=['object'])\n",
    "\n",
    "X[chg_to_numer] = X[chg_to_numer].astype('float64')\n",
    "X[chg_to_category] = X[chg_to_category].astype('object')\n",
    "\n",
    "testset[chg_to_numer] = testset[chg_to_numer].astype('float64')\n",
    "testset[chg_to_category] = testset[chg_to_category].astype('object')\n",
    "\n",
    "continous_num = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                 '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                 'EnclosedPorch', '3SsnPorch',\t'ScreenPorch',\t'PoolArea',\t'MiscVal']\n",
    "\n",
    "time_based_num = ['MoSold', 'YrSold', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt']\n",
    "\n",
    "discrete_num = list(set(chg_to_numer) - set(continous_num) - set(time_based_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closer Outlier Analysis for making robust trees\n",
    "for col in continous_num:\n",
    "    plot_outlier_analysis(X[col], y['SalePrice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming X is your DataFrame and y is your Series\n",
    "# X = pd.DataFrame([...])\n",
    "# y = pd.Series([...])\n",
    "\n",
    "# One-hot encode the categorical variables in X\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Concatenate X_encoded and y\n",
    "data = pd.concat([X_encoded, y], axis=1)\n",
    "data2 = pd.concat([X[chg_to_numer], y], axis=1)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = data2.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "# plt.title('Feature and Target Correlation Heatmap')\n",
    "# plt.show()\n",
    "(~corr_matrix[corr_matrix > 0.8].isnull()).sum().sort_values(ascending=False)\n",
    "# corr_matrix['GrLivArea'].sort_values(ascending=False)\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(12, 9))\n",
    "# sns.heatmap(corrmat, vmax=.8, square=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessors\n",
    "# from importlib import reload\n",
    "# reload(preprocessors)\n",
    "\n",
    "from preprocessors import missing_imputers, feat_engg\n",
    "\n",
    "imputer = missing_imputers()\n",
    "feat_engg = feat_engg(trainset=X, testset=testset)\n",
    "\n",
    "cols_list = [numerical_selector, chg_to_category]\n",
    "prep8 = feat_engg.prep8(*cols_list)\n",
    "\n",
    "# X_prep = prep8.fit_transform(X)\n",
    "\n",
    "# dtr = DecisionTreeRegressor().fit(X_prep, y)\n",
    "\n",
    "dtr = Pipeline(\n",
    "    [\n",
    "        ('prep', prep8),\n",
    "        ('tree', DecisionTreeRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "dtr.fit(X, y)\n",
    "\n",
    "# joblib.dump(dtr, 'models/base_decisiontree.pkl')\n",
    "\n",
    "\n",
    "tree_preds = pd.DataFrame(dtr.predict(testset), columns=['SalePrice'])\n",
    "# tree_preds = np.exp(tree_preds)\n",
    "tree_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "path = dtr[1].cost_complexity_pruning_path(dtr[0].fit_transform(X), y)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "# ccp_alphas[:-1]\n",
    "# ccp_alphas\n",
    "path = pd.DataFrame(path)\n",
    "path.sort_values(by=['ccp_alphas'])\n",
    "# path = path[path['impurities'] <= 100000000]\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "clfs = []\n",
    "for ccp_alpha in tqdm(ccp_alphas):\n",
    "\n",
    "    dtr = Pipeline(\n",
    "        [\n",
    "            ('prep', prep8),\n",
    "            ('tree', DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # clf = dtr[1].set_params(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    dtr.fit(X, y)\n",
    "    clfs.append(dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clfs[-1][1].tree_.node_count\n",
    "# ccp_alphas[:100]\n",
    "# clfs[4]\n",
    "# for pipeline in clfs:\n",
    "#     node_count = pipeline[1].tree_.node_count\n",
    "node_counts = [node_count for pipeline in clfs for node_count in [pipeline[1].tree_.node_count]]\n",
    "depth = [max_depth for pipeline in clfs for max_depth in [pipeline[1].tree_.max_depth]]\n",
    "# depth = [clf.tree_.max_depth for clf in clfs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [node_count for pipeline in clfs for node_count in [pipeline[1].tree_.node_count]]\n",
    "depth = [max_depth for pipeline in clfs for max_depth in [pipeline[1].tree_.max_depth]]\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run gridsearch over values of alpha {0, 100000000}\n",
    "dir(clfs[1])\n",
    "\n",
    "#params\n",
    "# 'tree__ccp_alpha': 0.8561643835616438,\n",
    "#  'tree__criterion': 'squared_error',\n",
    "#  'tree__max_depth': None, full tree 25\n",
    "#  'tree__max_features': None,\n",
    "#  'tree__max_leaf_nodes': None, <3000\n",
    "#  'tree__min_impurity_decrease': 0.0,\n",
    "#  'tree__min_samples_leaf': 1,\n",
    "#  'tree__min_samples_split': 2,\n",
    "#  'tree__min_weight_fraction_leaf': 0.0,\n",
    "#  'tree__monotonic_cst': None,\n",
    "#  'tree__random_state': 0,\n",
    "#  'tree__splitter': 'best'\n",
    "\n",
    "clfs[1].get_params()\n",
    "\n",
    "dtr = Pipeline(\n",
    "        [\n",
    "            ('prep', prep8),\n",
    "            ('tree', DecisionTreeRegressor(random_state=0))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "params = {\n",
    "    'tree__ccp_alpha': ccp_alphas.to_list(),\n",
    "    'tree__max_depth': [15],\n",
    "    'tree__min_samples_split': [50],\n",
    "    'tree__min_samples_leaf': [10],\n",
    "    'tree__random_state': [0],\n",
    "    \n",
    "}\n",
    "\n",
    "gridcv_res = GridSearchCV(estimator = dtr, \n",
    "             param_grid = params,\n",
    "            scoring=('neg_mean_squared_error'), \n",
    "            n_jobs=-1,\n",
    "            refit=True, \n",
    "            cv=None, \n",
    "            verbose=1, \n",
    "            return_train_score=True)\n",
    "\n",
    "\n",
    "gridcv_res.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(gridcv_res.cv_results_).sort_values(by = ['rank_test_score'])\n",
    "gridcv_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.set_params(**gridcv_res.best_params_)\n",
    "# dtr.set_params(tree__ccp_alpha = 3764042.0495960824, tree__min_samples_split= 50)\n",
    "# dtr.set_params(tree__ccp_alpha = 13981182.229896478)\n",
    "# dtr.set_params(tree__ccp_alpha = 699162.1819960608)\n",
    "# dtr.set_params(tree__ccp_alpha = 0)\n",
    "# dtr.fit(X, y)\n",
    "cv_res_best_model = cross_validate(dtr, \n",
    "               X, y,\n",
    "               cv = 5,\n",
    "               scoring=('neg_mean_squared_error'),\n",
    "               return_train_score=True)\n",
    "pd.DataFrame(cv_res_best_model)\n",
    "\n",
    "dtr.fit(X, y)\n",
    "\n",
    "residual_plots(dtr, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtr[1].tree_.max_depth\n",
    "df = pd.DataFrame(gridcv_res.cv_results_).sort_values(by=['rank_test_score'])[['param_tree__ccp_alpha', 'mean_test_score', 'mean_train_score', 'std_test_score', 'std_train_score', 'rank_test_score']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample data (replace this with your actual DataFrame)\n",
    "# df = pd.DataFrame({\n",
    "#     'param_tree__ccp_alpha': [...],\n",
    "#     'mean_test_score': [...],\n",
    "#     'mean_train_score': [...],\n",
    "#     'std_test_score': [...],\n",
    "#     'std_train_score': [...]\n",
    "# })\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot mean train score\n",
    "sns.lineplot(x='param_tree__ccp_alpha', y='mean_train_score', data=df, label='Mean Train Score', marker='o')\n",
    "\n",
    "# Plot mean test score\n",
    "sns.lineplot(x='param_tree__ccp_alpha', y='mean_test_score', data=df, label='Mean Test Score', marker='o')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Effect of param_tree__ccp_alpha on Mean Train and Test Scores')\n",
    "plt.xlabel('param_tree__ccp_alpha')\n",
    "plt.ylabel('Mean Score')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING MODELS AND PREDICT FOR SUBMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtr[1].get_params()\n",
    "# with open('models/base_decisiontree_1_pre_post_pruning.pkl', 'wb') as f: \n",
    "#     dill.dump(dtr, f)\n",
    "\n",
    "# tree_preds = pd.DataFrame(dtr.predict(testset), columns=['SalePrice'])\n",
    "# fulltestset[['Id']].join(tree_preds)\n",
    "# fulltestset[['Id']].join(tree_preds).to_csv('submissions/base_decisiontree_1_pre_post_pruning.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
